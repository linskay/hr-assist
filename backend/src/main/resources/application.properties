# ===================================================================
# LLM Provider Configuration
# ===================================================================

# The active LLM provider. Can be 'openai', 'gemini', 'djl', or 'llama'.
llm.provider=openai

# --- OpenAI Configuration ---
openai.api.key=<YOUR_OPENAI_API_KEY>
openai.model=gpt-4

# --- Google Gemini Configuration ---
gemini.api.key=<YOUR_GEMINI_API_KEY>
gemini.model=gemini-pro

# --- Llama Configuration ---
# This could be a self-hosted endpoint or a third-party provider API
llama.api.url=http://localhost:11434/api/generate
llama.model=llama3

# ===================================================================
# Server Configuration
# ===================================================================
server.port=8080
